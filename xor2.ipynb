{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Dec 13 00:50:45 2019\n",
        "\n",
        "@author: Amina Asif\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Dec 11 20:38:44 2019\n",
        "\n",
        "@author: Amina Asif\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score as auc_roc\n",
        "\n",
        "\n",
        "\n",
        "import itertools\n",
        "import warnings\n",
        "\n",
        "def plotit(X,Y=None,clf=None,  conts = None, ccolors = ('b','k','r'), colors = ('c','y'), markers = ('s','o'), hold = False, transform = None,**kwargs):\n",
        "    \"\"\"\n",
        "    @author: Dr. Fayyaz Minhas\n",
        "    @author-email: afsar at pieas dot edu dot pk\n",
        "    2D Scatter Plotter for Classification\n",
        "    A function for showing data scatter plot and classification boundary\n",
        "    of a classifier for 2D data\n",
        "        X: nxd  matrix of data points\n",
        "        Y: (optional) n vector of class labels\n",
        "        clf: (optional) classification/discriminant function handle\n",
        "        conts: (optional) contours (if None, contours are drawn for each class boundary)\n",
        "        ccolors: (optional) colors for contours   \n",
        "        colors: (optional) colors for each class (sorted wrt class id)\n",
        "            can be 'scaled' or 'random' or a list/tuple of color ids\n",
        "        markers: (optional) markers for each class (sorted wrt class id)\n",
        "        hold: Whether to hold the plot or not for overlay (default: False).\n",
        "        transform: (optional) a function handle for transforming data before passing to clf\n",
        "        kwargs: any keyword arguments to be passed to clf (if any)        \n",
        "    \"\"\"\n",
        "    if clf is not None and X.shape[1]!=2:\n",
        "        warnings.warn(\"Data Dimensionality is not 2. Unable to plot.\")\n",
        "        return\n",
        "    if markers is None:\n",
        "        markers = ('.',)\n",
        "        \n",
        "    d0,d1 = (0,1)\n",
        "    minx, maxx = np.min(X[:,d0]), np.max(X[:,d0])\n",
        "    miny, maxy = np.min(X[:,d1]), np.max(X[:,d1])\n",
        "    eps=1e-6\n",
        "\n",
        "    \n",
        "    if Y is not None:\n",
        "        classes = sorted(set(Y))\n",
        "        if conts is None:\n",
        "            conts = list(classes)        \n",
        "        vmin,vmax = classes[0]-eps,classes[-1]+eps\n",
        "    else:\n",
        "        vmin,vmax=-2-eps,2+eps\n",
        "        if conts is None:            \n",
        "            conts = sorted([-1+eps,0,1-eps])\n",
        "        \n",
        "    if clf is not None:\n",
        "        npts = 150\n",
        "        x = np.linspace(minx,maxx,npts)\n",
        "        y = np.linspace(miny,maxy,npts)\n",
        "        t = np.array(list(itertools.product(x,y)))\n",
        "        if transform is not None:\n",
        "            t = transform(t)\n",
        "        t=Variable(torch.from_numpy(t)).type(torch.FloatTensor)\n",
        "        z = clf(t,**kwargs)\n",
        "        \n",
        "        z = np.reshape(z.numpy(),(npts,npts)).T        \n",
        "        extent = [minx,maxx,miny,maxy]\n",
        "        \n",
        "        plt.contour(x,y,z,conts,linewidths = [2],colors=ccolors,extent=extent, label='f(x)=0')\n",
        "        #plt.imshow(np.flipud(z), extent = extent, cmap=plt.cm.Purples, vmin = -2, vmax = +2); plt.colorbar()\n",
        "        plt.pcolormesh(x, y, z,cmap=plt.cm.Purples,vmin=vmin,vmax=vmax);plt.colorbar()\n",
        "        plt.axis([minx,maxx,miny,maxy])\n",
        "    \n",
        "    if Y is not None:        \n",
        "        for i,y in enumerate(classes):\n",
        "            if colors is None or colors=='scaled':\n",
        "                cc = np.array([[i,i,i]])/float(len(classes))\n",
        "            elif colors =='random':\n",
        "                cc = np.array([[np.random.rand(),np.random.rand(),np.random.rand()]])\n",
        "            else:\n",
        "                cc = colors[i%len(colors)]\n",
        "            mm = markers[i%len(markers)]\n",
        "            plt.scatter(X[Y==y,d0],X[Y==y,d1], marker = mm,c = cc, s = 30)     \n",
        "         \n",
        "    else:\n",
        "        plt.scatter(X[:,d0],X[:,d1],marker = markers[0], c = 'k', s = 5)\n",
        "    plt.xlabel('$x_1$')\n",
        "    plt.ylabel('$x_2$')   \n",
        "    if not hold:\n",
        "        plt.grid()        \n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def loss_rej(y, h, r=1, c=0):\n",
        "    if type(r)!=type(1):\n",
        "        r=np.array(r)\n",
        "    l_total=np.mean(np.sum(((y*h)<=0)*(r>0)+c*(r<=0)))\n",
        "    l_rejection=np.mean(np.sum(c*(r<=0)))\n",
        "    return l_total, l_rejection\n",
        "\n",
        "def hinge(y_true, y_pred):\n",
        "    zero = torch.Tensor([0]) \n",
        "#    import pdb; pdb.set_trace()\n",
        "#    return torch.mean(torch.max(zero, 1 - y_true * y_pred))\n",
        "    return torch.max(zero, 1 - y_true * y_pred)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,d):\n",
        "        super(Net, self).__init__()\n",
        "        self.hidden1 = nn.Linear(d,10)  \n",
        "#        self.hidden2 = nn.Linear(10,10)  \n",
        "        self.out = nn.Linear(10,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "#        x = x.view(x.size(0), -1)\n",
        "        x = self.hidden1(x)\n",
        "        x = F.tanh(x)\n",
        "#        x = self.hidden2(x)\n",
        "#        x = F.tanh(x)\n",
        "        \n",
        "        x = self.out(x)\n",
        "#        x = F.tanh(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class RejNet(nn.Module):\n",
        "    def __init__(self,d):\n",
        "        super(RejNet, self).__init__()\n",
        "        self.hidden1 = nn.Linear(d,10)  \n",
        "        self.hidden2 = nn.Linear(10,100)  \n",
        "        self.out = nn.Linear(100,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "#        x = x.view(x.size(0), -1)\n",
        "        x = self.hidden1(x)\n",
        "        x = F.tanh(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = F.tanh(x)\n",
        "        \n",
        "        x = self.out(x)\n",
        "        x = F.tanh(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "###################Generate Data######################\n",
        "d=1.50\n",
        "n=500\n",
        "X1=np.random.randn(n,2)+d*np.array([1,1])\n",
        "l1=[1.0]*len(X1)\n",
        "\n",
        "X2=np.random.randn(n,2)+d*np.array([1,-1])\n",
        "l2=[-1.0]*len(X2)\n",
        "\n",
        "X3=np.random.randn(n,2)+d*np.array([-1,1])\n",
        "l3=[-1.0]*len(X3)\n",
        "\n",
        "\n",
        "X4=np.random.randn(n,2)+d*np.array([-1,-1])\n",
        "l4=[1.0]*len(X4)\n",
        "\n",
        "\n",
        "\n",
        "data=np.vstack((X1, X2, X3, X4))\n",
        "labels=np.array(l1+l2+l3+l4)\n",
        "\n",
        "pos=np.vstack((X1,X4))\n",
        "neg=np.vstack((X2,X3))\n",
        "#plt.scatter(pos[:,0], pos[:,1])\n",
        "#plt.scatter(neg[:,0], neg[:,1])\n",
        "\n",
        "\n",
        "Xtr=Variable(torch.from_numpy(data)).type(torch.FloatTensor)\n",
        "\n",
        "Ytr=Variable(torch.from_numpy(labels)).type(torch.FloatTensor)\n",
        "\n",
        "############## Train classifier#########################\n",
        "\n",
        "class_epochs=50000\n",
        "mlp_class=Net(Xtr.shape[1])\n",
        "optimizer = optim.Adam(mlp_class.parameters())\n",
        "\n",
        "zero=np.zeros(Ytr.shape)\n",
        "zero=Variable(torch.from_numpy(zero)).type(torch.FloatTensor)\n",
        "\n",
        "mlp_rej=RejNet(Xtr.shape[1])\n",
        "optimizer_rej = optim.Adam(mlp_rej.parameters(), lr=0.0001)\n",
        "c=0.650\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "L=[]\n",
        "\n",
        "for epoch in range(class_epochs):\n",
        "            # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = mlp_class(Xtr)\n",
        "\n",
        "    \n",
        "    h = torch.squeeze(mlp_class(Xtr),1)\n",
        "    r=torch.squeeze(mlp_rej(Xtr),1)\n",
        "    e = hinge(Ytr,h)\n",
        "    \n",
        "    l1 = torch.max(r+e,c*(1-r))\n",
        "  \n",
        "\n",
        "    loss_r=torch.mean(torch.max(zero, l1 ))    \n",
        "  \n",
        "    L.append(loss_r.data.numpy())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    optimizer_rej.zero_grad()\n",
        "    loss_r.backward()\n",
        "    optimizer.step()\n",
        "    optimizer_rej.step()\n",
        "    \n",
        "plt.close('all')\n",
        "plt.plot(L)\n",
        "plt.title('Loss')\n",
        "plt.grid()\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')    \n",
        "    \n",
        "for param in mlp_class.parameters():\n",
        "    param.requires_grad =False\n",
        "        \n",
        "for param in mlp_rej.parameters():\n",
        "    param.requires_grad =False\n",
        "     \n",
        "\n",
        "    \n",
        "X=Xtr\n",
        "Y=Ytr\n",
        "\n",
        "y_p= mlp_class(X)\n",
        "y_p=y_p.detach()\n",
        "y_r=mlp_rej(X)\n",
        "y_r=y_r.detach()\n",
        "y_r=y_r.numpy().flatten()\n",
        "y_p2=y_p.numpy().flatten()\n",
        "Y=np.array(Y)\n",
        "auc_c=auc_roc(Y, y_p2)\n",
        "auc_r=auc_roc(Y[y_r>0], y_p2[y_r>0])\n",
        "\n",
        "print(\"AUC without rejection=\", auc_c)\n",
        "print(\"AUC with rejection=\", auc_r)\n",
        "\n",
        "print (\"Number of examples rejected=\", len(y_r[y_r<0]), \"/\", len(y_r))\n",
        "\n",
        "\n",
        "#plt.close('all')\n",
        "plt.figure()\n",
        "X2=np.array(X)\n",
        "plotit(X2,Y,clf=mlp_rej, transform = None, conts =[0], ccolors = ['g'], hold = False )\n",
        "plt.figure()\n",
        "plotit(X2,Y,clf=mlp_class, transform = None, conts =[-1,0,1])\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}